
# apply_tuned: apply the tuned-adm peformance tuning for RHS.
#
function apply_tuned(){

  local out; local err
  local TUNE_PROFILE='rhs-high-throughput'
  local TUNE_DIR="/etc/tune-profiles/$TUNE_PROFILE"
  local TUNE_FILE='ktune.sh'
  local TUNE_PATH="$TUNE_DIR/$TUNE_FILE"
  local TUNE_PATH_BAK="$TUNE_PATH.orig"
  local TUNE_PERMS=755 # rwxr-xr-x

  # set MATCH_DIR and MATCH_FILE vars if match
  match_dir "$TUNE_FILE" "$SUBDIR_FILES"
  [[ -z "$MATCH_DIR" ]] && {
        display "INFO: $TUNE_FILE file not supplied" $LOG_INFO
        return; }

  cd $MATCH_DIR

  # replace ktune.sh
  [[ -f $TUNE_PATH_BAK ]] || mv $TUNE_PATH $TUNE_PATH_BAK
  out="$(cp -f $TUNE_FILE $TUNE_PATH)"
  err=$?
  display "$TUNE_FILE cp: $out" $LOG_DEBUG
  if [[ ! -f $TUNE_PATH ]] ; then
    display "ERROR: cp of $TUNE_FILE to $TUNE_DIR error $err" $LOG_FORCE
    exit 13
  fi
  chmod $TUNE_PERMS $TUNE_PATH

  # run profile
  out="$(tuned-adm profile $TUNE_PROFILE 2>&1)"
  err=$?
  display "tuned-adm: $out" $LOG_DEBUG
  if (( err != 0 )) ; then
    display "ERROR: tuned-adm error $err" $LOG_FORCE
    exit 15
  fi
  cd -
}

# install_plugin: if a plugin jar file is provided in any of the included sub-
# directories then copy it to the correct location. Otherwise, yum install the
# rhs-hadoop plugin package, which also copies the jar file to the correct
# directory.
# NOTE: not currently invoked since the rhs-hadoop plugin package is now part
#   of the RHS 2.1.1+ ISO.
#
function install_plugin(){

  local PLUGIN_JAR='glusterfs-hadoop-.*.jar' # note: regexp not glob
  local PLUGIN_PKG='rhs-hadoop'
  local USR_JAVA_DIR='/usr/share/java'
  local HADOOP_JAVA_DIR='/usr/lib/hadoop/lib/'
  local jar=''; local out; local err

  # set MATCH_DIR and MATCH_FILE vars if match
  match_dir "$PLUGIN_JAR" "$SUBDIR_FILES"
  if [[ -n "$MATCH_DIR" ]]; then  # found packaged plugin jar file
    cd $MATCH_DIR
    jar="$MATCH_FILE"
    display "-- Installing Gluster-Hadoop plug-in ($jar)..." $LOG_INFO

    # create target dirs if they does not exist
    [[ -d $USR_JAVA_DIR ]]    || mkdir -p $USR_JAVA_DIR
    [[ -d $HADOOP_JAVA_DIR ]] || mkdir -p $HADOOP_JAVA_DIR

    # copy jar and create symlink
    out="$(cp -uf $jar $USR_JAVA_DIR 2>&1)"
    err=$?
    display "plugin cp: $out" $LOG_DEBUG
    if (( err != 0 )) ; then
      display "ERROR: plugin copy error $err" $LOG_FORCE
      exit 5
    fi

    rm -f $HADOOP_JAVA_DIR/$jar
    out="$(ln -s $USR_JAVA_DIR/$jar $HADOOP_JAVA_DIR/$jar 2>&1)"
    err=$?
    display "plugin symlink: $out" $LOG_DEBUG
    if (( err != 0 )) ; then
      display "ERROR: plugin symlink error $err" $LOG_FORCE
      exit 7
    fi
    cd -

  elif yum -q $PLUGIN_PKG >&/dev/null ; then # pgk available
    # yum install rhs-hadoop pkg
    out="$(yum -y install $PLUGIN_PKG)"
    err=$?
    display "yum install $PLUGIN_PKG plugin: $out" $LOG_INFO
    if (( err != 0 )) ; then
      display "ERROR: yum install error $err" $LOG_FORCE
      exit 8
    fi

  else
    display "ERROR: \"$PLUGIN_PKG\" package is not available" $LOG_FORCE
    display "       This package contains the hadoop plugin" $LOG_FORCE
    exit 9
  fi
  display "   ... $PLUGIN_PKG plugin install successful" $LOG_SUMMARY
}
